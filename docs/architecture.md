# Architecture

## Overview

The RAG Ops Platform is a serverless RAG system built on AWS. It ingests documents, chunks and embeds them into pgvector, and serves retrieval + generation queries via a REST API.

## Data Flow

```
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   S3 (Documents)    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ 1. Upload docs
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway â”‚â”€â”€â”€â”€â–¶â”‚     Ingest Lambda (Python)    â”‚
â”‚ POST /ingest â”‚     â”‚  download â†’ chunk â†’ embed â†’   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  upsert into pgvector         â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ 2. Store embeddings
                                    â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Aurora Serverless v2        â”‚
                     â”‚  (Postgres 16 + pgvector)    â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                     â”‚  â”‚documentsâ”‚ â”‚   chunks    â”‚ â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ 3. Vector search
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway â”‚â”€â”€â”€â”€â–¶â”‚     Query Lambda (Python)     â”‚
â”‚ POST /query  â”‚     â”‚  embed question â†’ search â†’    â”‚
â”‚ GET  /health â”‚     â”‚  assemble context â†’ generate  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Provider Strategy

The platform uses abstract interfaces (`EmbeddingProvider`, `LLMProvider`) so the AI provider can be swapped with a config change:

| Provider | Embedding Model | LLM Model | Status |
|----------|----------------|-----------|--------|
| OpenAI | text-embedding-3-small (1536d) | gpt-4o-mini | âœ… MVP |
| Bedrock | Titan Embeddings v2 (1024d) | Claude 3 Haiku | ğŸ”œ v2 |

## Security

- IAM least privilege (separate roles for query vs ingest)
- Secrets Manager for DB credentials (auto-managed by Aurora)
- S3 encryption (KMS) + public access blocking
- Input validation + character limits
- No secrets in code or config files

## Cost Controls

- Aurora Serverless v2: min 0.5 ACU (scales near-zero when idle)
- SHA256 document caching (skip re-embedding unchanged docs)
- Batched embedding API calls
- Configurable `max_tokens` and `top_k` limits
- Retrieval-only mode (no LLM cost for testing)
